{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202902/202902 [00:00<00:00, 556756.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5400778/5400778 [00:07<00:00, 728776.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5400778/5400778 [00:06<00:00, 832387.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10933016/10933016 [00:07<00:00, 1485641.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10933016/10933016 [00:04<00:00, 2290195.19it/s]\n",
      "100%|██████████| 10933016/10933016 [00:10<00:00, 1057124.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n",
      "519\n",
      "90993\n",
      "(90993, 670)\n",
      "(90993,)\n",
      "(90993, 670)\n"
     ]
    }
   ],
   "source": [
    "# 载入原始用户移动端行为数据\n",
    "import pandas as pd\n",
    "base_path = '/home/liyouru/.ipython/profile_myserver/Dataset/JDD/'\n",
    "path_t_user = base_path + 'user.csv'\n",
    "path_t_order = base_path + 't_order.csv'\n",
    "path_t_loan_sum = base_path + 't_loan_sum.csv'\n",
    "path_t_loan = base_path + 't_loan.csv'\n",
    "path_t_click = base_path + 't_click.csv'\n",
    "path_submit_sample = base_path + 'Loan_Forecasting.csv'\n",
    "\n",
    "# 用户基本信息\n",
    "user_df = pd.read_csv(path_t_user, header=0, sep=',')\n",
    "# 购买记录\n",
    "order_df = pd.read_csv(path_t_order, header=0, sep=',')\n",
    "# 点击记录\n",
    "click_df = pd.read_csv(path_t_click,header=0, sep=',')\n",
    "# 借贷历史\n",
    "loan_df = pd.read_csv(path_t_loan,header=0, sep=',')\n",
    "# 借贷月度统计\n",
    "loan_sum_df = pd.read_csv(path_t_loan_sum,header=0, sep=',')\n",
    "# 提交用户uid\n",
    "uid = []\n",
    "with open(path_submit_sample, 'rb') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        line = line.strip().split(',')\n",
    "        uid.append(int(line[0]))\n",
    "        \n",
    "def show_data_stru():\n",
    "    print (user_df.shape)\n",
    "    print user_df.head()\n",
    "    print '-------------------------------------------------------------'\n",
    "    print (order_df.shape)\n",
    "    print order_df.head()\n",
    "    print '-------------------------------------------------------------'\n",
    "    print (click_df.shape)\n",
    "    print click_df.head()\n",
    "    print '-------------------------------------------------------------'\n",
    "    print (loan_df.shape)\n",
    "    print loan_df.head()\n",
    "    print '-------------------------------------------------------------'\n",
    "    print (loan_sum_df.shape)\n",
    "    print loan_sum_df.head()\n",
    "    \n",
    "#show_data_stru()\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "\n",
    "base_feature = []\n",
    "\n",
    "# 年龄——0\n",
    "base_feature.append(list(user_df['age']))\n",
    "# 性别——1\n",
    "base_feature.append(list(user_df['sex']))\n",
    "# 限额——2\n",
    "base_feature.append(list(user_df['limit']))\n",
    "\n",
    "def detla_date(date,T_month,T_day):\n",
    "    d1 = date\n",
    "    d2 = datetime.datetime(2016, T_month, T_day)\n",
    "    return (d1 - d2).days\n",
    "\n",
    "active_duration = []\n",
    "for each in list(user_df['active_date']):\n",
    "    if each == '0' or 'nan':\n",
    "        each = '2016/5/1'\n",
    "    active_duration.append(abs(detla_date(datetime.datetime.strptime(each, \"%Y/%m/%d\"),11,30)))\n",
    "\n",
    "# 激活时长——3\n",
    "base_feature.append(active_duration)\n",
    "\n",
    "print len(base_feature)\n",
    "\n",
    "loan_time = list(loan_df['loan_time'])\n",
    "loan_amount = list(loan_df['loan_amount'])\n",
    "loan_plannum = list(loan_df['plannum'])\n",
    "loan_uid_temp = list(loan_df['uid'])\n",
    "loan_uid = []\n",
    "for i in range(len(loan_uid_temp)):\n",
    "    loan_uid.append(int(loan_uid_temp[i]))\n",
    "\n",
    "month_index_loan = ['08','09','10','11']\n",
    "\n",
    "def get_loan_feature(loan_uid,loan_time,loan_amount,month_index_loan):\n",
    "    loan_monthly_feature = []\n",
    "    uid_loan_map = {}\n",
    "    \n",
    "    # 初始化一键多值map\n",
    "    for i in range(len(uid)):\n",
    "        for j in range(12):\n",
    "            uid_loan_map.setdefault(uid[i],[]).append(0)\n",
    "    \n",
    "    # 计算每个uid月度点击总量\n",
    "    for i in tqdm(range(len(loan_uid))):\n",
    "        if loan_time[i][5:7] == month_index_loan[0]:\n",
    "            # 钱数\n",
    "            uid_loan_map[loan_uid[i]][0] += loan_amount[i]\n",
    "            # 次数\n",
    "            uid_loan_map[loan_uid[i]][1] += 1\n",
    "            # 期数\n",
    "            uid_loan_map[loan_uid[i]][2] += loan_plannum[i]\n",
    "        elif loan_time[i][5:7] == month_index_loan[1]:\n",
    "            # 钱数\n",
    "            uid_loan_map[loan_uid[i]][3] += loan_amount[i]\n",
    "            # 次数\n",
    "            uid_loan_map[loan_uid[i]][4] += 1\n",
    "            # 期数\n",
    "            uid_loan_map[loan_uid[i]][5] += loan_plannum[i]        \n",
    "        elif loan_time[i][5:7] == month_index_loan[2]:\n",
    "            # 钱数\n",
    "            uid_loan_map[loan_uid[i]][6] += loan_amount[i]\n",
    "            # 次数\n",
    "            uid_loan_map[loan_uid[i]][7] += 1\n",
    "            # 期数\n",
    "            uid_loan_map[loan_uid[i]][8] += loan_plannum[i]\n",
    "        elif loan_time[i][5:7] == month_index_loan[3]:\n",
    "            # 钱数\n",
    "            uid_loan_map[loan_uid[i]][9] += loan_amount[i]\n",
    "            # 次数\n",
    "            uid_loan_map[loan_uid[i]][10] += 1\n",
    "            # 期数\n",
    "            uid_loan_map[loan_uid[i]][11] += loan_plannum[i]\n",
    "    \n",
    "    # 保存点击量特征向量\n",
    "    c_feature_1 = []\n",
    "    c_feature_2 = []\n",
    "    c_feature_3 = []\n",
    "    c_feature_4 = []\n",
    "    c_feature_5 = []\n",
    "    c_feature_6 = []\n",
    "    c_feature_7 = []\n",
    "    c_feature_8 = []\n",
    "    c_feature_9 = []\n",
    "    c_feature_10 = []\n",
    "    c_feature_11 = []\n",
    "    c_feature_12 = []\n",
    "    \n",
    "    for i in range(len(uid)):\n",
    "        c_feature_1.append(uid_loan_map[uid[i]][0])\n",
    "        c_feature_2.append(uid_loan_map[uid[i]][1])\n",
    "        if uid_loan_map[uid[i]][1] != 0:\n",
    "            c_feature_3.append(int(uid_loan_map[uid[i]][2]/uid_loan_map[uid[i]][1]))\n",
    "        else:\n",
    "            c_feature_3.append(0)\n",
    "        c_feature_4.append(uid_loan_map[uid[i]][3])\n",
    "        c_feature_5.append(uid_loan_map[uid[i]][4])\n",
    "        if uid_loan_map[uid[i]][4] != 0:\n",
    "            c_feature_6.append(int(uid_loan_map[uid[i]][5]/uid_loan_map[uid[i]][4]))\n",
    "        else:\n",
    "            c_feature_6.append(0)\n",
    "        c_feature_7.append(uid_loan_map[uid[i]][6])\n",
    "        c_feature_8.append(uid_loan_map[uid[i]][7])\n",
    "        if uid_loan_map[uid[i]][7] != 0:\n",
    "            c_feature_9.append(int(uid_loan_map[uid[i]][8]/uid_loan_map[uid[i]][7]))\n",
    "        else:\n",
    "            c_feature_9.append(0)\n",
    "        c_feature_10.append(uid_loan_map[uid[i]][9])\n",
    "        c_feature_11.append(uid_loan_map[uid[i]][10])\n",
    "        if uid_loan_map[uid[i]][10] != 0:\n",
    "            c_feature_12.append(int(uid_loan_map[uid[i]][11]/uid_loan_map[uid[i]][10]))\n",
    "        else:\n",
    "            c_feature_12.append(0)\n",
    "\n",
    "    # 并入时序特征\n",
    "    loan_monthly_feature.append(c_feature_1)\n",
    "    loan_monthly_feature.append(c_feature_2)\n",
    "    loan_monthly_feature.append(c_feature_3)\n",
    "    loan_monthly_feature.append(c_feature_4)\n",
    "    loan_monthly_feature.append(c_feature_5)\n",
    "    loan_monthly_feature.append(c_feature_6)\n",
    "    loan_monthly_feature.append(c_feature_7)\n",
    "    loan_monthly_feature.append(c_feature_8)\n",
    "    loan_monthly_feature.append(c_feature_9)\n",
    "    loan_monthly_feature.append(c_feature_10)\n",
    "    loan_monthly_feature.append(c_feature_11)\n",
    "    loan_monthly_feature.append(c_feature_12)\n",
    "    return loan_monthly_feature\n",
    "\n",
    "loan_feature = get_loan_feature(loan_uid,loan_time,loan_amount,month_index_loan)\n",
    "\n",
    "loan_8_10 = []\n",
    "loan_9_11 = []\n",
    "\n",
    "loan_8_10.extend(loan_feature[:9])\n",
    "loan_9_11.extend(loan_feature[3:12])\n",
    "print len(loan_8_10)\n",
    "print len(loan_9_11)\n",
    "\n",
    "# df_loan_8_10 = pd.DataFrame(np.transpose(np.asarray(loan_8_10)))\n",
    "# df_loan_8_10.to_csv(base_path + 'df_loan_8_10.csv')\n",
    "\n",
    "# df_loan_9_11 = pd.DataFrame(np.transpose(np.asarray(loan_9_11)))\n",
    "# df_loan_9_11.to_csv(base_path + 'df_loan_9_11.csv')\n",
    "\n",
    "order_time = list(order_df['buy_time'])\n",
    "order_qty = list(order_df['qty'])\n",
    "order_price = list(order_df['price'])\n",
    "order_discount = list(order_df['discount'])\n",
    "\n",
    "order_uid_temp = list(order_df['uid'])\n",
    "order_uid = []\n",
    "for i in range(len(order_uid_temp)):\n",
    "    order_uid.append(int(order_uid_temp[i]))\n",
    "\n",
    "month_index_order = ['08','09','10','11']\n",
    "\n",
    "def get_order_feature(click_uid,click_time,order_price,order_qty,month_index_order):\n",
    "    order_monthly_feature = []\n",
    "    uid_order_map = {}\n",
    "    \n",
    "    # 初始化一键多值map\n",
    "    for i in range(len(uid)):\n",
    "        for j in range(4):\n",
    "            uid_order_map.setdefault(uid[i],[]).append(0)\n",
    "    \n",
    "    # 计算每个uid月度点击总量\n",
    "    for i in tqdm(range(len(order_uid))):\n",
    "        if order_time[i][5:7] == month_index_order[0]:\n",
    "            uid_order_map[order_uid[i]][0] += order_price[i] * order_qty[i] - order_discount[i]\n",
    "        elif order_time[i][5:7] == month_index_order[1]:\n",
    "            uid_order_map[order_uid[i]][1] += order_price[i] * order_qty[i] - order_discount[i]\n",
    "        elif order_time[i][5:7] == month_index_order[2]:\n",
    "            uid_order_map[order_uid[i]][2] += order_price[i] * order_qty[i] - order_discount[i]\n",
    "        elif order_time[i][5:7] == month_index_order[3]:\n",
    "            uid_order_map[order_uid[i]][3] += order_price[i] * order_qty[i] - order_discount[i]\n",
    "    \n",
    "    # 保存点击量特征向量\n",
    "    c_feature_1 = []\n",
    "    c_feature_2 = []\n",
    "    c_feature_3 = []\n",
    "    c_feature_4 = []\n",
    "    \n",
    "    for i in range(len(uid)):\n",
    "        c_feature_1.append(uid_order_map[uid[i]][0])\n",
    "        c_feature_2.append(uid_order_map[uid[i]][1])\n",
    "        c_feature_3.append(uid_order_map[uid[i]][2])\n",
    "        c_feature_4.append(uid_order_map[uid[i]][3])\n",
    "\n",
    "    # 并入时序特征\n",
    "    order_monthly_feature.append(c_feature_1)\n",
    "    order_monthly_feature.append(c_feature_2)\n",
    "    order_monthly_feature.append(c_feature_3)\n",
    "    order_monthly_feature.append(c_feature_4)\n",
    "    return order_monthly_feature\n",
    "\n",
    "order_feature = get_order_feature(order_uid,order_time,order_price,order_qty,month_index_order)\n",
    "\n",
    "order_8_10 = []\n",
    "order_9_11 = []\n",
    "\n",
    "order_8_10.extend(order_feature[:3])\n",
    "order_9_11.extend(order_feature[1:4])\n",
    "\n",
    "# 缺失值补充\n",
    "def get_nan2zero(souce_list):\n",
    "    for each in souce_list:\n",
    "        for i in range(len(each)):\n",
    "            for j in range(len(each[0])):\n",
    "                if math.isnan(each[i][j]):\n",
    "                    each[i][j] = 0\n",
    "\n",
    "souce_list = [order_8_10,order_9_11]\n",
    "get_nan2zero(souce_list)\n",
    "\n",
    "print len(order_8_10)\n",
    "print len(order_8_10)\n",
    "\n",
    "# df_order_8_10 = pd.DataFrame(np.transpose(np.asarray(order_8_10)))\n",
    "# df_order_8_10.to_csv(base_path + 'df_order_8_10.csv')\n",
    "\n",
    "# df_order_9_11 = pd.DataFrame(np.transpose(np.asarray(order_9_11)))\n",
    "# df_order_9_11.to_csv(base_path + 'df_order_9_11.csv')\n",
    "\n",
    "order_cata_id_temp = list(order_df['cate_id'])\n",
    "order_cata_id = []\n",
    "for each in order_cata_id_temp:\n",
    "    order_cata_id.append(int(each))\n",
    "\n",
    "# print len(order_cata_id)\n",
    "# res={}\n",
    "# for i in order_cata_id:\n",
    "#     res[i] = res.get(i,0)+1\n",
    "# print res\n",
    "\n",
    "month_index_order = ['08','09','10','11']\n",
    "\n",
    "def get_order_cata_id_feature(order_uid,order_time,order_cata_id,order_qty,month_index_order):\n",
    "    order_cata_id_monthly_feature = []\n",
    "    uid_order_cata_id_map = {}\n",
    "    \n",
    "    # 初始化一键多值map\n",
    "    for i in range(len(uid)):\n",
    "        for j in range(176):\n",
    "            uid_order_cata_id_map.setdefault(uid[i],[]).append(0)\n",
    "    \n",
    "    # 计算每个uid月度cata_id的one-hot特征\n",
    "    for i in tqdm(range(len(order_uid))):\n",
    "        if order_time[i][5:7] == month_index_order[0]:\n",
    "            uid_order_cata_id_map[order_uid[i]][order_cata_id[i] - 1] += order_qty[i]\n",
    "        elif order_time[i][5:7] == month_index_order[1]:\n",
    "            uid_order_cata_id_map[order_uid[i]][order_cata_id[i] - 1 + 44] += order_qty[i]\n",
    "        elif order_time[i][5:7] == month_index_order[2]:\n",
    "            uid_order_cata_id_map[order_uid[i]][order_cata_id[i] - 1 + 88] += order_qty[i]\n",
    "        elif order_time[i][5:7] == month_index_order[3]:\n",
    "            uid_order_cata_id_map[order_uid[i]][order_cata_id[i] - 1 + 132] += order_qty[i]\n",
    "    \n",
    "    for i in range(176):\n",
    "        temp = []\n",
    "        for j in range(len(uid)):\n",
    "            temp.append(uid_order_cata_id_map[uid[j]][i])\n",
    "        order_cata_id_monthly_feature.append(temp)\n",
    "    \n",
    "    return order_cata_id_monthly_feature\n",
    "\n",
    "order_cata_id_feature = get_order_cata_id_feature(order_uid,order_time,order_cata_id,order_qty,month_index_order)\n",
    "\n",
    "order_cata_id_8_10 = []\n",
    "order_cata_id_9_11 = []\n",
    "\n",
    "order_cata_id_8_10.extend(order_cata_id_feature[:132])\n",
    "order_cata_id_9_11.extend(order_cata_id_feature[44:])\n",
    "\n",
    "print len(order_cata_id_8_10)\n",
    "print len(order_cata_id_9_11)\n",
    "\n",
    "# df_order_cata_id_8_10 = pd.DataFrame(np.transpose(np.asarray(order_cata_id_8_10)))\n",
    "# df_order_cata_id_8_10.to_csv(base_path + 'df_order_cata_id_8_10.csv')\n",
    "\n",
    "# df_order_cata_id_9_11 = pd.DataFrame(np.transpose(np.asarray(order_cata_id_9_11)))\n",
    "# df_order_cata_id_9_11.to_csv(base_path + 'df_order_cata_id_9_11.csv')\n",
    "\n",
    "click_time = list(click_df['click_time'])\n",
    "\n",
    "click_uid_temp = list(click_df['uid'])\n",
    "click_uid = []\n",
    "for i in range(len(click_uid_temp)):\n",
    "    click_uid.append(int(click_uid_temp[i]))\n",
    "\n",
    "month_index_order = ['08','09','10','11']\n",
    "\n",
    "def get_click_feature(click_uid,click_time,month_index_order):\n",
    "    click_monthly_feature = []\n",
    "    uid_click_map = {}\n",
    "    \n",
    "    # 初始化一键多值map\n",
    "    for i in range(len(uid)):\n",
    "        for j in range(4):\n",
    "            uid_click_map.setdefault(uid[i],[]).append(0)\n",
    "    \n",
    "    # 计算每个uid月度点击总量\n",
    "    for i in tqdm(range(len(click_uid))):\n",
    "        if click_time[i][5:7] == month_index_order[0]:\n",
    "            uid_click_map[click_uid[i]][0] += 1\n",
    "        elif click_time[i][5:7] == month_index_order[1]:\n",
    "            uid_click_map[click_uid[i]][1] += 1\n",
    "        elif click_time[i][5:7] == month_index_order[2]:\n",
    "            uid_click_map[click_uid[i]][2] += 1\n",
    "        elif click_time[i][5:7] == month_index_order[3]:\n",
    "            uid_click_map[click_uid[i]][3] += 1\n",
    "    \n",
    "    # 保存点击量特征向量\n",
    "    c_feature_1 = []\n",
    "    c_feature_2 = []\n",
    "    c_feature_3 = []\n",
    "    c_feature_4 = []\n",
    "    \n",
    "    for i in range(len(uid)):\n",
    "        c_feature_1.append(uid_click_map[uid[i]][0])\n",
    "        c_feature_2.append(uid_click_map[uid[i]][1])\n",
    "        c_feature_3.append(uid_click_map[uid[i]][2])\n",
    "        c_feature_4.append(uid_click_map[uid[i]][3])\n",
    "\n",
    "    # 并入时序特征\n",
    "    click_monthly_feature.append(c_feature_1)\n",
    "    click_monthly_feature.append(c_feature_2)\n",
    "    click_monthly_feature.append(c_feature_3)\n",
    "    click_monthly_feature.append(c_feature_4)\n",
    "    return click_monthly_feature\n",
    "\n",
    "click_feature = get_click_feature(click_uid,click_time,month_index_order)\n",
    "\n",
    "click_8_10 = []\n",
    "click_9_11 = []\n",
    "\n",
    "click_8_10.extend(click_feature[:3])\n",
    "click_9_11.extend(click_feature[1:4])\n",
    "print len(click_8_10)\n",
    "print len(click_9_11)\n",
    "\n",
    "# df_click_8_10 = pd.DataFrame(np.transpose(np.asarray(click_8_10)))\n",
    "# df_click_8_10.to_csv(base_path + 'df_click_8_10.csv')\n",
    "\n",
    "# df_click_9_11 = pd.DataFrame(np.transpose(np.asarray(click_9_11)))\n",
    "# df_click_9_11.to_csv(base_path + 'df_click_9_11.csv')\n",
    "\n",
    "click_pid_temp = list(click_df['pid'])\n",
    "click_pid = []\n",
    "for each in click_pid_temp:\n",
    "    click_pid.append(int(each))\n",
    "\n",
    "click_param_temp = list(click_df['param'])\n",
    "click_param = []\n",
    "for each in click_param_temp:\n",
    "    click_param.append(int(each))\n",
    "\n",
    "# 获得所有pid_param pairs\n",
    "pid_param_map = {}\n",
    "for i in tqdm(range(len(click_pid))):\n",
    "    pid_param_map.setdefault(click_pid[i],[]).append(click_param[i])\n",
    "    \n",
    "# 除重\n",
    "pid_param_pair = []\n",
    "for i in range(10):\n",
    "    pid_param_pair.append(list(set(pid_param_map[i + 1])))\n",
    "\n",
    "# 多键一值map: pid + param --> index\n",
    "pid_param_pair_order = {}\n",
    "index = 0\n",
    "for i in range(10):\n",
    "    for each in pid_param_pair[i]:\n",
    "        pid_param_pair_order[i + 1,each] = index\n",
    "        index += 1\n",
    "\n",
    "# 窗口月份表\n",
    "month_index_click = ['08','09','10','11']\n",
    "\n",
    "def get_click_pid_param_cross_feature(click_uid,click_time,click_pid,click_param,month_index_click):\n",
    "    click_pid_monthly_feature = []\n",
    "    uid_click_pid_map = {}\n",
    "    \n",
    "    # 初始化一键多值map\n",
    "    for i in range(len(uid)):\n",
    "        for j in range(692):\n",
    "            uid_click_pid_map.setdefault(uid[i],[]).append(0)\n",
    "    \n",
    "    # 计算每个uid月度click_pid_param的one-hot交叉特征\n",
    "    for i in tqdm(range(len(click_uid))):\n",
    "        if click_time[i][5:7] == month_index_click[0]:\n",
    "            uid_click_pid_map[click_uid[i]][pid_param_pair_order[click_pid[i],click_param[i]]] += 1\n",
    "        elif click_time[i][5:7] == month_index_click[1]:\n",
    "            uid_click_pid_map[click_uid[i]][pid_param_pair_order[click_pid[i],click_param[i]] + 173] += 1\n",
    "        elif click_time[i][5:7] == month_index_click[2]:\n",
    "            uid_click_pid_map[click_uid[i]][pid_param_pair_order[click_pid[i],click_param[i]] + 346] += 1\n",
    "        elif click_time[i][5:7] == month_index_click[3]:\n",
    "            uid_click_pid_map[click_uid[i]][pid_param_pair_order[click_pid[i],click_param[i]] + 519] += 1\n",
    "    \n",
    "    for i in range(692):\n",
    "        temp = []\n",
    "        for j in range(len(uid)):\n",
    "            temp.append(uid_click_pid_map[uid[j]][i])\n",
    "        click_pid_monthly_feature.append(temp)\n",
    "    \n",
    "    return click_pid_monthly_feature\n",
    "\n",
    "click_pid_feature = get_click_pid_param_cross_feature(click_uid,click_time,click_pid,click_param,month_index_click)\n",
    "\n",
    "click_pid_8_10 = []\n",
    "click_pid_9_11 = []\n",
    "\n",
    "click_pid_8_10.extend(click_pid_feature[:519])\n",
    "click_pid_9_11.extend(click_pid_feature[173:])\n",
    "\n",
    "print len(click_pid_8_10)\n",
    "print len(click_pid_9_11)\n",
    "\n",
    "# df_click_pid_8_10 = pd.DataFrame(np.transpose(np.asarray(click_pid_8_10)))\n",
    "# df_click_pid_8_10.to_csv(base_path + 'df_click_pid_8_10.csv')\n",
    "\n",
    "# df_click_pid_9_11 = pd.DataFrame(np.transpose(np.asarray(click_pid_9_11)))\n",
    "# df_click_pid_9_11.to_csv(base_path + 'df_click_pid_9_11.csv')\n",
    "\n",
    "loan_sum_map = {}\n",
    "loan_sum = list(loan_sum_df['loan_sum'])\n",
    "loan_id = list(loan_sum_df['uid'])\n",
    "for i in range(len(loan_id)):\n",
    "    loan_id[i] = int(loan_id[i])\n",
    "\n",
    "VALUE = []\n",
    "for i in range(len(uid)):\n",
    "    VALUE.append(0)\n",
    "\n",
    "for i in range(len(loan_sum)):\n",
    "    loan_sum_map[loan_id[i]] = loan_sum[i]\n",
    "\n",
    "for i in range(len(uid)):\n",
    "    if uid[i] in loan_id:\n",
    "        VALUE[i] = loan_sum_map[uid[i]]\n",
    "        \n",
    "print len(VALUE)\n",
    "\n",
    "# 数据准备(特征合并)\n",
    "feature = []\n",
    "feature.extend(base_feature)\n",
    "feature.extend(loan_8_10)\n",
    "feature.extend(order_8_10)\n",
    "feature.extend(click_8_10)\n",
    "feature.extend(order_cata_id_8_10)\n",
    "feature.extend(click_pid_8_10)\n",
    "\n",
    "feature_t = []\n",
    "feature_t.extend(base_feature)\n",
    "feature_t.extend(loan_9_11)\n",
    "feature_t.extend(order_9_11)\n",
    "feature_t.extend(click_9_11)\n",
    "feature_t.extend(order_cata_id_9_11)\n",
    "feature_t.extend(click_pid_9_11)\n",
    "\n",
    "\n",
    "X = np.transpose(np.asarray(feature))\n",
    "y = np.asarray(VALUE)\n",
    "X_t = np.transpose(np.asarray(feature_t))\n",
    "\n",
    "print X.shape\n",
    "print y.shape\n",
    "print X_t.shape\n",
    "\n",
    "# 保存特征数据\n",
    "# df_X = pd.DataFrame(X)\n",
    "# df_y = pd.DataFrame(y)\n",
    "# df_X_t = pd.DataFrame(X_t)\n",
    "\n",
    "# df_X.to_csv(base_path + 'save_feature_X.csv')\n",
    "# df_y.to_csv(base_path + 'save_feature_y.csv')\n",
    "# df_X_t.to_csv(base_path + 'save_feature_X_t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90993, 670)\n",
      "(90993,)\n",
      "(90993, 670)\n"
     ]
    }
   ],
   "source": [
    "# 数据准备(特征合并)\n",
    "feature = []\n",
    "feature.extend(base_feature)\n",
    "feature.extend(loan_8_10)\n",
    "feature.extend(order_8_10)\n",
    "feature.extend(click_8_10)\n",
    "feature.extend(order_cata_id_8_10)\n",
    "feature.extend(click_pid_8_10)\n",
    "\n",
    "feature_t = []\n",
    "feature_t.extend(base_feature)\n",
    "feature_t.extend(loan_9_11)\n",
    "feature_t.extend(order_9_11)\n",
    "feature_t.extend(click_9_11)\n",
    "feature_t.extend(order_cata_id_9_11)\n",
    "feature_t.extend(click_pid_9_11)\n",
    "\n",
    "\n",
    "X = np.transpose(np.asarray(feature))\n",
    "y = np.asarray(VALUE)\n",
    "X_t = np.transpose(np.asarray(feature_t))\n",
    "\n",
    "print X.shape\n",
    "print y.shape\n",
    "print X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((72794, 670), (18199, 670), (72794,), (18199,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy as sp\n",
    "import time\n",
    "\n",
    "# 初始化基模型\n",
    "m_gbrt1 = RandomForestRegressor(n_estimators = 200,max_depth = 4, n_jobs = 8)\n",
    "m_gbrt2 = RandomForestRegressor(n_estimators = 250,max_depth = 5, n_jobs = 8)\n",
    "m_rf1 = RandomForestRegressor(n_estimators = 200,max_depth = 5, n_jobs = 8)\n",
    "m_rf2 = RandomForestRegressor(n_estimators = 300,max_depth = 6, n_jobs = 8)\n",
    "\n",
    "# 训练集、验证集划分\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
    "print (X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "# Staking 模型\n",
    "def get_stacking_regressor_feature(split_num, X_train, Y_train, X_test):\n",
    "    gbrt1 = []\n",
    "    gbrt2 = []\n",
    "    rf1 = []\n",
    "    rf2 = []\n",
    "\n",
    "    gbrt11 = []\n",
    "    gbrt22 = []\n",
    "    rf11 = []\n",
    "    rf22 = []\n",
    "\n",
    "    Stacking_Feature = [] \n",
    "    kf = KFold(n_splits = split_num)\n",
    "\n",
    "    # 使用k折方法对基模型的预测结果整合成新的特征矩阵并再次训练7个基模型\n",
    "    t0 = time.time()\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        # 训练基模型\n",
    "        print 'training...'\n",
    "        m_gbrt1.fit(X_train[train_index],Y_train[train_index])\n",
    "        print 'training time 1:',time.time() - t0\n",
    "        m_gbrt2.fit(X_train[train_index],Y_train[train_index])\n",
    "        print 'training time 2:',time.time() - t0\n",
    "        m_rf1.fit(X_train[train_index],Y_train[train_index])\n",
    "        print 'training time 3:',time.time() - t0\n",
    "        m_rf2.fit(X_train[train_index],Y_train[train_index])\n",
    "        print 'training time 4:',time.time() - t0\n",
    "\n",
    "        # 得到基模型上的预测结果\n",
    "        gbrt1.extend(m_gbrt1.predict(X_train[test_index])) \n",
    "        gbrt2.extend(m_gbrt2.predict(X_train[test_index]))\n",
    "        rf1.extend(m_rf1.predict(X_train[test_index]))\n",
    "        rf2.extend(m_rf2.predict(X_train[test_index]))\n",
    "\n",
    "        # 在测试集上得到预测\n",
    "        gbrt11.append(m_gbrt1.predict(X_test)) \n",
    "        gbrt22.append(m_gbrt2.predict(X_test))\n",
    "        rf11.append(m_rf1.predict(X_test))\n",
    "        rf22.append(m_rf2.predict(X_test))\n",
    "\n",
    "    index = [gbrt1, gbrt2, rf1, rf2]\n",
    "    for i in range(split_num):\n",
    "        Stacking_Feature.append(index[i])\n",
    "    \n",
    "    # 训练集stacking特征\n",
    "    result = []\n",
    "    result.append(np.transpose(np.asarray(Stacking_Feature)))\n",
    "    \n",
    "    index2 = [gbrt11, gbrt22, rf11, rf22]\n",
    "    Test_Feature = []\n",
    "    for each in index2:\n",
    "        temp = []\n",
    "        for i in range(18199):\n",
    "            temp.append((each[0][i] + each[1][i] + each[2][i] + each[3][i]) / 4)\n",
    "        Test_Feature.append(temp)\n",
    "    \n",
    "    # 测试集stacking特征\n",
    "    result.append(np.transpose(np.asarray(Test_Feature)))\n",
    "    return result\n",
    "\n",
    "def RMSE(Y_test, Y_Vali):  \n",
    "    return sp.sqrt(sp.mean((Y_test - Y_Vali) ** 2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "training time 1: 55.1191208363\n",
      "training time 2: 146.490036964\n",
      "training time 3: 211.461251974\n",
      "training time 4: 323.02481389\n",
      "training...\n",
      "training time 1: 383.46083498\n",
      "training time 2: 468.656931877\n",
      "training time 3: 536.771714926\n",
      "training time 4: 645.664548874\n",
      "training...\n",
      "training time 1: 700.214148045\n",
      "training time 2: 779.337954998\n",
      "training time 3: 842.926918983\n",
      "training time 4: 1062.70441198\n",
      "training...\n",
      "training time 1: 1178.02826595\n",
      "training time 2: 1348.64397693\n",
      "training time 3: 1481.41004181\n",
      "training time 4: 1707.66443682\n",
      "(72794, 4) (18199, 4)\n",
      "1.80678745831\n"
     ]
    }
   ],
   "source": [
    "# 再次训练基模型\n",
    "stacking_result = []\n",
    "stacking_result = get_stacking_regressor_feature(4, X_train, Y_train, X_test)\n",
    "print stacking_result[0].shape,stacking_result[1].shape\n",
    "m_gbrt1.fit(stacking_result[0],Y_train)\n",
    "Y_Vali = m_gbrt1.predict(stacking_result[1])\n",
    "\n",
    "print RMSE(Y_test, Y_Vali)\n",
    "# # # 在测试集上输出预测结果\n",
    "# # GBRT.fit(X,y)\n",
    "# # y_t = GBRT.predict(X_t)\n",
    "\n",
    "# value_predict = []\n",
    "# for i in range(len(uid)):\n",
    "#     value_predict.append(max(0,float(y_t[i])))\n",
    "\n",
    "# with open(base_path + 'submit_1211.csv', 'wb') as f:\n",
    "#     for i in range(len(uid)):\n",
    "#         f.write('{},{}\\n'.format(uid[i], value_predict[i]))\n",
    "        \n",
    "# print 'done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.81557535053\n"
     ]
    }
   ],
   "source": [
    "GBRT = GradientBoostingRegressor(n_estimators=200, max_depth=4)\n",
    "best = RandomForestRegressor(n_estimators = 500,max_depth = 5, n_jobs = 8)\n",
    "GBRT.fit(stacking_result[0],Y_train)\n",
    "y_t = GBRT.predict(stacking_result[1])\n",
    "print RMSE(Y_test, y_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
